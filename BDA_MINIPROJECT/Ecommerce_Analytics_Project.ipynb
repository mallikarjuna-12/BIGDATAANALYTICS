{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4bd10b9",
   "metadata": {},
   "source": [
    "# ðŸ›’ E-Commerce Analytics Project (Pandas + PySpark)\n",
    "---\n",
    "This notebook performs data analysis on `ecommerce_sample500.csv`, replicating the structure of the *Employees Office Data Analytics* PDF.\n",
    "\n",
    "**Steps Covered:**\n",
    "1. Import libraries\n",
    "2. Load and explore dataset\n",
    "3. Perform Pandas-based EDA\n",
    "4. Visualization with Matplotlib\n",
    "5. PySpark-based distributed analytics\n",
    "6. Export results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd2bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum as _sum, avg as _avg, countDistinct, to_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f4a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "csv_path = \"ecommerce_sample500.csv\"  # Update path if needed\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert InvoiceDate to datetime\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
    "\n",
    "# Add computed column\n",
    "df['Revenue'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bccb9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nMissing values per column:\\n\", df.isnull().sum())\n",
    "print(\"\\nBasic statistics:\\n\", df.describe(include='number').T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b81b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic KPIs\n",
    "total_orders = df['InvoiceNo'].nunique()\n",
    "unique_customers = df['CustomerID'].nunique()\n",
    "total_revenue = df['Revenue'].sum()\n",
    "avg_order_value = df.groupby('InvoiceNo')['Revenue'].sum().mean()\n",
    "\n",
    "print(f\"Total Orders: {total_orders}\\nUnique Customers: {unique_customers}\\nTotal Revenue: {total_revenue:.2f}\\nAOV: {avg_order_value:.2f}\")\n",
    "\n",
    "# Top products by revenue\n",
    "top_products = df.groupby(['StockCode','Description'])['Revenue'].sum().reset_index().sort_values('Revenue', ascending=False)\n",
    "top_products.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deec424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_dir = \"outputs\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Quantity distribution\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(df['Quantity'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Quantity Distribution')\n",
    "plt.xlabel('Quantity')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(f\"{out_dir}/quantity_distribution.png\")\n",
    "plt.show()\n",
    "\n",
    "# Revenue by top 10 countries\n",
    "country_sales = df.groupby('Country')['Revenue'].sum().sort_values(ascending=False).head(10)\n",
    "plt.figure(figsize=(8,5))\n",
    "country_sales.plot(kind='bar', color='coral', edgecolor='black')\n",
    "plt.title('Top 10 Countries by Revenue')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Total Revenue')\n",
    "plt.savefig(f\"{out_dir}/top_countries_revenue.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19567008",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName(\"EcommerceAnalysis\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "spark_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(csv_path)\n",
    "spark_df = spark_df.withColumn(\"Revenue\", col(\"Quantity\") * col(\"UnitPrice\"))\n",
    "\n",
    "spark_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Spark Aggregations\n",
    "agg_summary = spark_df.agg(\n",
    "    _sum(\"Revenue\").alias(\"total_revenue\"),\n",
    "    countDistinct(\"InvoiceNo\").alias(\"total_orders\"),\n",
    "    countDistinct(\"CustomerID\").alias(\"unique_customers\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"Total Revenue: {agg_summary['total_revenue']:.2f}\\nTotal Orders: {agg_summary['total_orders']}\\nUnique Customers: {agg_summary['unique_customers']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e18456",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Top products by revenue (Spark)\n",
    "top_products_spark = spark_df.groupBy(\"StockCode\", \"Description\").agg(_sum(\"Revenue\").alias(\"Revenue\")).orderBy(col(\"Revenue\").desc())\n",
    "top_products_spark.show(10)\n",
    "\n",
    "# Country-level revenue\n",
    "country_sales_spark = spark_df.groupBy(\"Country\").agg(_sum(\"Revenue\").alias(\"TotalRevenue\"), _avg(\"Revenue\").alias(\"AvgRevenue\")).orderBy(col(\"TotalRevenue\").desc())\n",
    "country_sales_spark.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c789cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save outputs\n",
    "output_dir = \"outputs_spark\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Fix for Windows Hadoop native I/O issue\n",
    "spark.conf.set(\"spark.hadoop.io.nativeio.enabled\", \"false\")\n",
    "\n",
    "# Write outputs safely\n",
    "top_products_spark.coalesce(1).write.option(\"header\", True).mode(\"overwrite\").csv(f\"{output_dir}/top_products\")\n",
    "country_sales_spark.coalesce(1).write.option(\"header\", True).mode(\"overwrite\").csv(f\"{output_dir}/country_sales\")\n",
    "\n",
    "spark.stop()\n",
    "print(f\"âœ… Results saved in '{output_dir}' folder.\")\n"
   ]
  }
 ],
 "metadata": {
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
